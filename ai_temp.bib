@inproceedings{Knickrehm2023-mq,
  title     = {The Role of Emotions in Human-{AI} Collaboration},
  author    = {Knickrehm, Charlott and Reichmann, Doron},
  booktitle = {ICIS 2023},
  year      = 2023
}


@inproceedings{Henkenjohann2024-pz,
  title     = {Challenges in Collaboration with Generative {AI}: Interaction
               Patterns, Outcome Quality and Perceived Responsibility},
  author    = {Henkenjohann, Richard and Trenz, Manuel},
  booktitle = {ECIS 2024},
  year      = 2024
}

@article{Baird2021-as,
  title     = {The next generation of research on {IS} use: A theoretical
               framework of delegation to and from agentic {IS} artifacts},
  author    = {Baird, Aaron and Maruping, Likoebe M},
  journal   = {MIS Q},
  publisher = {MIS Quarterly},
  volume    = 45,
  number    = 1,
  pages     = {315--341},
  month     = mar,
  year      = 2021
}

@article{Fugener2022-ju,
  title     = {Cognitive challenges in human–artificial intelligence
               collaboration: Investigating the path toward productive
               delegation},
  author    = {Fügener, Andreas and Grahl, Jörn and Gupta, Alok and Ketter,
               Wolfgang},
  journal   = {Inf. Syst. Res.},
  publisher = {Institute for Operations Research and the Management Sciences
               (INFORMS)},
  volume    = 33,
  number    = 2,
  pages     = {678--696},
  abstract  = {A consensus is beginning to emerge that the next phase of
               artificial intelligence (AI) induction in business organizations
               will require humans to work with AI in a variety of work
               arrangements. This article explores the issues related to human
               capabilities to work with AI. A key to working in many work
               arrangements is the ability to delegate work to entities that can
               do them most efficiently. Modern AI can do a remarkable job of
               efficient delegation to humans because it knows what it knows
               well and what it does not. Humans, on the other hand, are poor
               judges of their metaknowledge and are not good at delegating
               knowledge work to AI—this might prove to be a big stumbling block
               to create work environments where humans and AI work together.
               Humans have often created machines to serve them. The sentiment
               is perhaps exemplified by Oscar Wilde’s statement that
               “civilization requires slaves…. Human slavery is wrong, insecure
               and demoralizing. On mechanical slavery, on the slavery of the
               machine, the future of the world depends.” However, the time has
               come when humans might switch roles with machines. Our study
               highlights capabilities that humans need to effectively work with
               AI and still be in control rather than just being directed.},
  month     = jun,
  year      = 2022,
  language  = {en}
}

@article{Fugener2021-ch,
  title     = {Will humans-in-the-loop become Borgs? Merits and pitfalls of
               working with {AI}},
  author    = {Fügener, Andreas and {University of Cologne} and Grahl, Jörn and
               Gupta, Alok and Ketter, Wolfgang and {University of Cologne} and
               {University of Minnesota} and {University of Cologne} and
               {Erasmus University}},
  journal   = {MISQ},
  publisher = {MIS Quarterly},
  volume    = 45,
  number    = 3,
  pages     = {1527--1556},
  abstract  = {We analyze how advice from an AI affects complementarities
               between humans and AI, in particular what humans know that an AI
               does not know: “unique human knowledge.” In a multi-method study
               consisting of an analytical model, experimental studies, and a
               simulation study, our main finding is that human choices converge
               toward similar responses improving individual accuracy. However,
               as overall individual accuracy of the group of humans improves,
               the individual unique human knowledge decreases. Based on this
               finding, we claim that humans interacting with AI behave like
               “Borgs,” that is, cyborg creatures with strong individual
               performance but no human individuality. We argue that the loss of
               unique human knowledge may lead to several undesirable outcomes
               in a host of human–AI decision environments. We demonstrate this
               harmful impact on the “wisdom of crowds.” Simulation results
               based on our experimental data suggest that groups of humans
               interacting with AI are far less effective as compared to human
               groups without AI assistance. We suggest mitigation techniques to
               create environments that can provide the best of both worlds
               (e.g., by personalizing AI advice). We show that such
               interventions perform well individually as well as in wisdom of
               crowds settings.},
  month     = sep,
  year      = 2021
}

@article{Bao2021-af,
  title    = {Investigating the relationship between {AI} and trust in
              human-{AI} collaboration},
  author   = {Bao, Ying and Cheng, Xusen and de Vreede, Triparna and Vreede, G},
  journal  = {HICSS},
  pages    = {1--10},
  abstract = {With the increasing development of information technology, the
              implementation of artificial intelligence (AI) has been widespread
              and has empowered virtual team collaboration by increasing
              collaboration efficiency and achieving superior collaboration
              results in recent years. Trust in the process of human-AI
              interaction has been identified as a challenge for team
              collaboration in this context. However, little research has
              investigated the relationship between human-AI interaction and
              trust. This study proposes a theoretical model of the relationship
              between human-AI interaction and team members’ trust during
              collaboration processes. We conclude that tea m members’ cognitive
              and emotional perceptions during the interaction process are
              associated with their trust towards AI. Moreover, the relationship
              could also be moderated by the specific AI implementation traits.
              Our model provides a holistic view of human-AI interaction and its
              association with team members’ trust in the context of team
              collaboration.},
  year     = 2021
}

@article{Gomez2025-bn,
  title     = {Human-{AI} collaboration is not very collaborative yet: a
               taxonomy of interaction patterns in {AI}-assisted decision making
               from a systematic review},
  author    = {Gomez, Catalina and Cho, Sue Min and Ke, Shichang and Huang,
               Chien-Ming and Unberath, Mathias},
  journal   = {Front. Comput. Sci.},
  publisher = {Frontiers Media SA},
  volume    = 6,
  abstract  = {Leveraging Artificial Intelligence (AI) in decision support
               systems has disproportionately focused on technological
               advancements, often overlooking the alignment between algorithmic
               outputs and human expectations. A human-centered perspective
               attempts to alleviate this concern by designing AI solutions for
               seamless integration with existing processes. Determining what
               information AI should provide to aid humans is vital, a concept
               underscored by explainable AI's efforts to justify AI
               predictions. However, how the information is presented, e.g., the
               sequence of recommendations and solicitation of interpretations,
               is equally crucial as complex interactions may emerge between
               humans and AI. While empirical studies have evaluated human-AI
               dynamics across domains, a common vocabulary for human-AI
               interaction protocols is lacking. To promote more deliberate
               consideration of interaction designs, we introduce a taxonomy of
               interaction patterns that delineate various modes of human-AI
               interactivity. We summarize the results of a systematic review of
               AI-assisted decision making literature and identify trends and
               opportunities in existing interactions across application domains
               from 105 articles. We find that current interactions are
               dominated by simplistic collaboration paradigms, leading to
               little support for truly interactive functionality. Our taxonomy
               offers a tool to understand interactivity with AI in
               decision-making and foster interaction designs for achieving
               clear communication, trustworthiness, and collaboration.},
  month     = jan,
  year      = 2025
}

@article{Kolomaznik2024-jq,
  title    = {The role of socio-emotional attributes in enhancing human-{AI}
              collaboration},
  author   = {Kolomaznik, Michal and Petrik, Vladimir and Slama, Michal and
              Jurik, Vojtech},
  journal  = {Front. Psychol.},
  volume   = 15,
  pages    = 1369957,
  abstract = {This article delves into the dynamics of human interaction with
              artificial intelligence (AI), emphasizing the optimization of
              these interactions to enhance human productivity. Employing a
              Grounded Theory Literature Review (GTLR) methodology, the study
              systematically identifies and analyzes themes from literature
              published between 2018 and 2023. Data were collected primarily
              from the Scopus database, with the Web of Science used to
              corroborate findings and include additional sources identified
              through a snowball effect. At the heart of this exploration is the
              pivotal role of socio-emotional attributes such as trust, empathy,
              rapport, user engagement, and anthropomorphization-elements
              crucial for the successful integration of AI into human
              activities. By conducting a comprehensive review of existing
              literature and incorporating case studies, this study illuminates
              how AI systems can be designed and employed to foster deeper trust
              and empathetic understanding between humans and machines. The
              analysis reveals that when AI systems are attuned to human
              emotional and cognitive needs, there is a marked improvement in
              collaborative efficiency and productivity. Furthermore, the paper
              discusses the ethical implications and potential societal impacts
              of fostering such human-AI relationships. It argues for a paradigm
              shift in AI development-from focusing predominantly on technical
              proficiency to embracing a more holistic approach that values the
              socio-emotional aspects of human-AI interaction. This shift could
              pave the way for more meaningful and productive collaborations
              between humans and AI, ultimately leading to advancements that are
              both technologically innovative and human-centric.},
  month    = oct,
  year     = 2024,
  keywords = {artificial intelligence as social actors; autonomous technology;
              human-like AI; human-robot interaction; perception of AI},
  language = {en}
}

@inproceedings{Mola2024-qp,
  title     = {The Impact of {AI}-Mediated Communication on Virtual Teams},
  author    = {Mola, Aline and Abramova, Olga},
  booktitle = {ECIS 2024},
  year      = 2024
}

@inproceedings{Fu2024-qj,
  title     = {From text to self: Users’ perception of {AIMC} tools on
               interpersonal communication and self},
  author    = {Fu, Yue and Foell, Sami and Xu, Xuhai and Hiniker, Alexis},
  booktitle = {Proceedings of the CHI Conference on Human Factors in Computing
               Systems},
  publisher = {ACM},
  address   = {New York, NY, USA},
  volume    = 1,
  pages     = {1--17},
  month     = may,
  year      = 2024
}

@article{Hohenstein2023-qm,
  title     = {Artificial intelligence in communication impacts language and
               social relationships},
  author    = {Hohenstein, Jess and Kizilcec, Rene F and DiFranzo, Dominic and
               Aghajari, Zhila and Mieczkowski, Hannah and Levy, Karen and
               Naaman, Mor and Hancock, Jeffrey and Jung, Malte F},
  journal   = {Sci. Rep.},
  publisher = {Springer Science and Business Media LLC},
  volume    = 13,
  number    = 1,
  pages     = 5487,
  abstract  = {Artificial intelligence (AI) is already widely used in daily
               communication, but despite concerns about AI's negative effects
               on society the social consequences of using it to communicate
               remain largely unexplored. We investigate the social consequences
               of one of the most pervasive AI applications, algorithmic
               response suggestions (``smart replies''), which are used to send
               billions of messages each day. Two randomized experiments provide
               evidence that these types of algorithmic recommender systems
               change how people interact with and perceive one another in both
               pro-social and anti-social ways. We find that using algorithmic
               responses changes language and social relationships. More
               specifically, it increases communication speed, use of positive
               emotional language, and conversation partners evaluate each other
               as closer and more cooperative. However, consistent with common
               assumptions about the adverse effects of AI, people are evaluated
               more negatively if they are suspected to be using algorithmic
               responses. Thus, even though AI can increase the speed of
               communication and improve interpersonal perceptions, the
               prevailing anti-social connotations of AI undermine these
               potential benefits if used overtly.},
  month     = apr,
  year      = 2023,
  language  = {en}
}

@article{Hancock2020-wt,
  title     = {{AI}-Mediated Communication: Definition, research agenda, and
               ethical considerations},
  author    = {Hancock, Jeffrey T and Naaman, Mor and Levy, Karen},
  journal   = {J. Comput. Mediat. Commun.},
  publisher = {Oxford University Press (OUP)},
  volume    = 25,
  number    = 1,
  pages     = {89--100},
  abstract  = {Abstract We define Artificial Intelligence-Mediated Communication
               (AI-MC) as interpersonal communication in which an intelligent
               agent operates on behalf of a communicator by modifying,
               augmenting, or generating messages to accomplish communication
               goals. The recent advent of AI-MC raises new questions about how
               technology may shape human communication and requires
               re-evaluation – and potentially expansion – of many of
               Computer-Mediated Communication’s (CMC) key theories, frameworks,
               and findings. A research agenda around AI-MC should consider the
               design of these technologies and the psychological, linguistic,
               relational, policy and ethical implications of introducing AI
               into human–human communication. This article aims to articulate
               such an agenda.},
  month     = mar,
  year      = 2020,
  language  = {en}
}

@inproceedings{Jakesch2019-hu,
  title     = {{AI}-Mediated Communication: How the Perception that Profile Text
               was Written by {AI} Affects Trustworthiness},
  author    = {Jakesch, Maurice and French, Megan and Ma, Xiao and Hancock,
               Jeffrey T and Naaman, Mor},
  booktitle = {Proceedings of the 2019 CHI Conference on Human Factors in
               Computing Systems},
  publisher = {ACM},
  address   = {New York, NY, USA},
  month     = may,
  year      = 2019
}

@article{Mieczkowski2021-ge,
  title     = {{AI}-Mediated Communication: Language use and interpersonal
               effects in a referential communication task},
  author    = {Mieczkowski, Hannah and Hancock, Jeffrey T and Naaman, Mor and
               Jung, Malte and Hohenstein, Jess},
  journal   = {Proc. ACM Hum. Comput. Interact.},
  publisher = {Association for Computing Machinery (ACM)},
  volume    = 5,
  number    = {CSCW1},
  pages     = {1--14},
  abstract  = {AI-Mediated Communication (AI-MC) is interpersonal communication
               that involves an artificially intelligent system that can modify,
               augment, or even generate content to achieve communicative and
               relational goals. AI-MC is increasingly involved in human
               communication and has the potential to impact core aspects of
               human communication, such as language production, interpersonal
               perception and task performance. Through a between-subjects
               experimental design we examine how these processes are influenced
               when integrating AI-generated language in the form of suggested
               text responses (Google's smart replies) into a text-based
               referential communication task. Our study replicates and extends
               the impacts of a positivity bias in AI-generated language and
               introduces the adjacency pair framework into the study of AI-MC.
               We also find preliminary yet mixed evidence to suggest that
               AI-generated language has the potential to undermine some
               dimensions of interpersonal perception, such as social
               attraction. This study contributes important concepts for future
               work in AI-MC and offers findings with implications for the
               design of AI systems in human-to-human communication.},
  month     = apr,
  year      = 2021,
  language  = {en}
}

@article{Hohenstein2020-xf,
  title     = {{AI} as a moral crumple zone: The effects of {AI}-mediated
               communication on attribution and trust},
  author    = {Hohenstein, Jess and Jung, Malte},
  journal   = {Comput. Human Behav.},
  publisher = {Elsevier BV},
  volume    = 106,
  number    = 106190,
  pages     = 106190,
  month     = may,
  year      = 2020,
  language  = {en}
}
